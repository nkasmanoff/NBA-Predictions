{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N Games Lookback\n",
    "\n",
    "\n",
    "This notebook hopes to identify how many games of lookback correspond to optimal amount, if at all, one can use to create a proxy for played games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies and dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = '../data/NBADATA.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rolling_correlations(data,ngames):\n",
    "    \"\"\"Determines the correlation between a team's performance in a\n",
    "    particular category compared to that team's split average over the previous ngames. \n",
    "    Use this function to determine optimal lookback period. \n",
    "    \n",
    "    data : df\n",
    "        Dataframe containing all the box scores over previous 5 season. \n",
    "        \n",
    "    ngames : int\n",
    "        Lookback splits. Ex: ngames=5 corresponds to team's splits over previous 5 games. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "#delete irrelevant columns (for this section), they will be useful for other pieces of the study but not here!\n",
    "    nba_explore = pd.read_csv(dataset)\n",
    "    del nba_explore['Unnamed: 0'],nba_explore['GAME_ID'],nba_explore['Date'],nba_explore['Team'],nba_explore['Home'],nba_explore['Away']\n",
    "    del nba_explore['OU'],nba_explore['TOTAL']\n",
    "\n",
    "#add some other potential columns, like efficency. \n",
    "    nba_explore['3P%'] = np.divide(nba_explore['3P'].values,nba_explore['3PA'].values) \n",
    "\n",
    "    nba_explore['FG%'] = np.divide(nba_explore['FG'].values,nba_explore['FGA'].values)\n",
    "    nba_explore['FT%'] = np.divide(nba_explore['FT'].values,nba_explore['FTA'].values)\n",
    "    nba_explore['TRB']  = nba_explore['OR'] + nba_explore['DR']\n",
    "\n",
    "    nba_explore['AST/TO'] = np.divide(nba_explore['AST'].values,nba_explore['TO'].values)\n",
    "\n",
    "\n",
    "    relevant_stats = []\n",
    "    for col in nba_explore.columns:\n",
    "        if col != 'PLUS_MINUS':\n",
    "           # print(col + \" Correlation to Outcome\")\n",
    "            corr = np.corrcoef(nba_explore[col],nba_explore['PLUS_MINUS'])\n",
    "            #print(corr[0][1])\n",
    "            if abs(corr[0][1]) < .1:\n",
    "                pass\n",
    "            else:\n",
    "                relevant_stats.append(col)\n",
    "        \n",
    "\n",
    "    print(\"Using a window of \" ,ngames, \" games. \")\n",
    "    data['AST/TO'] = np.divide(data['AST'].values,data['TO'].values)\n",
    "    data['3P%'] = np.divide(data['3P'].values,data['3PA'].values) \n",
    "    data['FG%'] = np.divide(data['FG'].values,data['FGA'].values)\n",
    "    data['FT%'] = np.divide(data['FT'].values,data['FTA'].values)\n",
    "    del data['Unnamed: 0'],data['TOTAL']\n",
    "   # del data['Date']\n",
    "    data = data.loc[data['GAME_ID'].values < 41300001] #genius! No playoff games now :)   \n",
    "    #del data['Team'] \n",
    "    #data = pd.get_dummies(data) #sometimes option to hot tcode team, but not yet. Seems like overfitting. \n",
    "    teams = data.Team.unique() #each nba team. \n",
    "#iterate over those teams, make a rolling window\n",
    "    nba_data = pd.DataFrame([])\n",
    "    season_ids = []\n",
    "    for i,val in enumerate(data['GAME_ID'].values):  #loop through every game\n",
    "        season_ids.append(str(val)[1:3])\n",
    "\n",
    "    data['Season_ID'] = season_ids #identify the unique seasons. \n",
    "\n",
    "    for team in teams:  #for each team\n",
    "       # print(team)\n",
    "    #get separate seasons here\n",
    "        team_data = data.loc[data['Team'] == team]  #this contains the box score of every team game from 2013 to 2018.\n",
    "        for season in data['Season_ID'].unique(): #this contains the box score of that team for that season. \n",
    "            #print(season)\n",
    "            team_season = team_data.loc[team_data['Season_ID'] == season]\n",
    "        \n",
    "            stuff_to_turn_into_avgs =  relevant_stats  #['OR', 'DR', 'TOT', 'PF', 'ST', 'TO', 'BL', '3P%', 'FG%', 'FT%']\n",
    "            for col in team_season.columns:\n",
    "                if col in stuff_to_turn_into_avgs:\n",
    "                        team_season['Rolling ' + col] = team_season[col].rolling(window=ngames).mean().shift(1)\n",
    "\n",
    "            #split each season up here, \n",
    "                    #if col != 'PTS':\n",
    "                    #    team_season['Rolling ' + col] = team_season[col].rolling(window=N_GAMES).mean().shift(1)\n",
    "\n",
    "                        del team_season[col]\n",
    "                    \n",
    "            nba_data =  nba_data.append(team_season)\n",
    "\n",
    "           # df = pd.concat([road_df,home_df],axis=1)\n",
    "#reorganize the dataset. \n",
    "    nba_data_splits = nba_data.sort_values(by = ['GAME_ID', 'Home','Away'], ascending=[True, True,False])\n",
    "\n",
    "    nba_data_splits.dropna(inplace=True)\n",
    "\n",
    "    del nba_data_splits['Home'], nba_data_splits['Away'], nba_data_splits['FGA'], nba_data_splits['3PA'], nba_data_splits['FTA'], nba_data_splits['OR'],nba_data_splits['PF']                                                                                                                                \n",
    "    del nba_data_splits['PLUS_MINUS'], nba_data_splits['OU'],nba_data_splits['Rolling SPREAD'],nba_data_splits['Season_ID']\n",
    "    nba_dataset = pd.read_csv(dataset)                                                                                                               \n",
    "    rolling_vals = nba_data_splits\n",
    "  #  print(rolling_vals.head())\n",
    "    game_vals = nba_dataset\n",
    "    merged = game_vals.merge(rolling_vals,on=['GAME_ID','Team'])\n",
    "    print(rolling_vals.columns)\n",
    "#   del merged['GAME_ID'],merged['Team'],merged['Home'],merged['Away'],merged['SPREAD']\n",
    "  #  print(\"do dates align? \")\n",
    " #   print(merged[['Date_x','Date_y']].values[0:10])\n",
    "    total_corr = 0\n",
    "    for col in merged:\n",
    "        try:\n",
    "            corr = np.corrcoef(merged[col],merged['Rolling ' + col])[0][1]\n",
    "            #print(col)\n",
    "            #print(corr)\n",
    "            total_corr += abs(corr)\n",
    "        except:\n",
    "            pass\n",
    "    return total_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a window of  1  games. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'NBADATA.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1f920c9e143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlookback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnba_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/NBADATA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtotal_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrolling_correlations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnba_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlookback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Correlation = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mngame_corrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-4c564fa2ed41>\u001b[0m in \u001b[0;36mrolling_correlations\u001b[0;34m(data, ngames)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Home'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Away'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FGA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'3PA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FTA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLUS_MINUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rolling SPREAD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnba_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Season_ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mnba_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NBADATA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mrolling_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnba_data_splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;31m#  print(rolling_vals.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'NBADATA.csv' does not exist"
     ]
    }
   ],
   "source": [
    "ngames = [1,3,5,10,15,22,30,40,50,60,75,81]  #various N Game split sizes. \n",
    "ngame_corrs = []\n",
    "for lookback in ngames:\n",
    "    nba_dataset = pd.read_csv('../data/NBADATA.csv')\n",
    "    total_corr = rolling_correlations(nba_dataset,lookback)\n",
    "    print(\"Total Correlation = \", total_corr)\n",
    "    ngame_corrs.append(total_corr)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "  \n",
    "plt.title('Correlation Between Splits and in Game Box Score')   \n",
    "plt.xlabel('N Games')\n",
    "plt.ylabel('Correlation')\n",
    "plt.plot(ngames,ngame_corrs,'bo--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
