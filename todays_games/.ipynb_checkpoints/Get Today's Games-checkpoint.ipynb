{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Create Functions to Grab today's games, then align and wrangle the data for machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from nba_py import Scoreboard\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_todays_games():\n",
    "    \n",
    "    today = datetime.now()\n",
    "    day = today.day\n",
    "    month = today.month\n",
    "    year = today.year\n",
    " \n",
    "    ex = Scoreboard(month=month,day=day,year=year)\n",
    "    games = ex.game_header()['GAMECODE']\n",
    "    matchups = []\n",
    "    matchups.append(['road','home'])\n",
    "    for game in games:\n",
    "        away_team = game[-6:-3]\n",
    "        home_team = game[-3:]\n",
    "\n",
    "        if away_team == 'BKN':\n",
    "            away_team = 'BRK'\n",
    "        if home_team == 'BKN':\n",
    "            home_team = 'BRK'\n",
    "        \n",
    "        matchups.append([away_team,home_team])\n",
    "        \n",
    "    return matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['road', 'home'],\n",
       " ['HOU', 'OKC'],\n",
       " ['BOS', 'PHX'],\n",
       " ['LAC', 'POR'],\n",
       " ['MIL', 'GSW']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_todays_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_todays_dataset_p1():\n",
    "    \"\"\"Creates a dataset identical to the one used for the ML modeling. This is done by scraping the ngames averages\n",
    "    of the teams just listed, along with the spread, and cominbing. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"Find teams. \n",
    "    \"\"\"\n",
    "    today = datetime.now()\n",
    "    day = today.day\n",
    "    month = today.month\n",
    "    year = today.year\n",
    "    \n",
    "    \n",
    "    matchups = get_todays_games()[1:]\n",
    "    \n",
    "    #matchups\n",
    "    import numpy as np\n",
    "    from nba_py import team\n",
    "    teams = team.TeamList()\n",
    "    teamids = teams.info()\n",
    "    teamids = teamids[:-15]\n",
    "    teamids = teamids[['TEAM_ID','ABBREVIATION']]\n",
    "    teamids = teamids.rename(index=str, columns={\"ABBREVIATION\": \"Team\"})\n",
    "    teamids = teamids.replace('BKN','BRK')\n",
    "    teamids = teamids.sort_values('Team')\n",
    "\n",
    "    todays_dataframe = []\n",
    "    for matchup in matchups:\n",
    "        game_array = []\n",
    "        for team_ in matchup:\n",
    "            TEAM_ID = teamids.loc[teamids['Team'] == team_].values[0,0]\n",
    "            #print(team_,TEAM_ID)\n",
    "        \n",
    "            TEAM_splits = team.TeamLastNGamesSplits(team_id=TEAM_ID,season='2018-19')\n",
    "       # print(TEAM_splits.last20())\n",
    "            df = TEAM_splits.last20()\n",
    "        \n",
    "            #retain (and create) the columns already proven to be statistically correlated to outcome. \n",
    "            df['AST/TO'] = df['AST']/df['TOV']\n",
    "\n",
    "            df = df[['FGM','FG3M','FTM','DREB','AST','STL',\n",
    "                     'TOV','BLK','PTS','AST/TO','FG3_PCT',\n",
    "                     'FG_PCT','FT_PCT']]\n",
    "           # df['AST/TO'] = df['AST']/df['TOV']\n",
    "            game_array.append(df.values)\n",
    "        \n",
    "        matchup_array = np.concatenate((game_array[0],game_array[1]),axis=1)\n",
    "        todays_dataframe.append(matchup_array)\n",
    "\n",
    "    #quick formating!\n",
    "    todays_dataframe = np.array(todays_dataframe)\n",
    "    todays_dataframe = todays_dataframe[:,0,:]\n",
    "    return todays_dataframe\n",
    "\n",
    "def scrape_espn_for_today_spreads(todays_dataframe):\n",
    "    \"\"\"Scrape and clean from ESPN, which has the info of all NBA games today and their lines. \n",
    "    \"\"\"\n",
    "    from bs4 import BeautifulSoup\n",
    "    import pandas as pd\n",
    "    import urllib\n",
    "    matchups = get_todays_games()[1:]\n",
    "\n",
    "\n",
    "    url  = \"http://www.espn.com/nba/lines/_/date\"\n",
    "    page = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    tables = soup.find_all('table')\n",
    "    table_df = pd.DataFrame([])\n",
    "    for table in tables:\n",
    "        table_df =table_df.append(pd.read_html(str(table)))\n",
    "\n",
    "    team_that_plays = []\n",
    "    spread_of_that_team = []\n",
    "    for i, row in enumerate(table_df[1]):\n",
    "        if row == 'SPREAD':\n",
    "            print(row)\n",
    "            try:\n",
    "                print(table_df[1][i+1])\n",
    "        \n",
    "                eh = table_df[1][i+1]\n",
    "            except: \n",
    "                eh = table_df[1][i+2]\n",
    "                print(eh)\n",
    "\n",
    "            sign = eh[0]\n",
    "            try:\n",
    "                spread, _ = eh[1:6].split('-')\n",
    "            except:\n",
    "                spread, _ = eh[1:6].split('+')\n",
    "\n",
    "       # spread, _ = eh[0:5].split('-')\n",
    "       # print(spread)\n",
    "           # print(sign + spread)\n",
    "            for i, char in enumerate(eh): \n",
    "                team = eh[i:i+3]\n",
    "\n",
    "                if char.isalpha():\n",
    "                    team = eh[i:i+3]\n",
    "                    if team[-1].isalpha() == False:\n",
    "                        if team == 'SA:':\n",
    "                            team = 'SAS'\n",
    "                        if team == 'NY:':\n",
    "                            team = 'NYK'\n",
    "                        if team == 'GS:':\n",
    "                            team = 'GSW'\n",
    "                    #print(team)\n",
    "\n",
    "                    break\n",
    "    \n",
    "              #  if eh[i+3].isalpha() == False:\n",
    "              #      print(team)\n",
    "              #      print(\"BAD!!\")\n",
    "               # team = eh[i:i+3]\n",
    "             ##   if team =='SA':\n",
    "             #       team = 'SAS'\n",
    "\n",
    "               # break\n",
    "                \n",
    "        \n",
    "        \n",
    "       # print(\"Spread of the game? \" , team, sign+spread)\n",
    "            team_that_plays.append(team)\n",
    "            spread_of_that_team.append(sign+spread)\n",
    "            \n",
    "    home_spread = []\n",
    "    print(\"TEAM THAT PLAYS:\")\n",
    "    print(team_that_plays)\n",
    "    for s,team in enumerate(team_that_plays):\n",
    "      #  print(team)\n",
    "        for game in matchups:\n",
    "            try:\n",
    "                ind = game.index(team)\n",
    "                if ind == 0:\n",
    "                  #  print(team + \" is on the road\")\n",
    "                 #   print(\"home spread is therefore opposite of \",float(spread_of_that_team[s]))\n",
    "                 #  print(\"home spread is therefore \",-float(spread_of_that_team[s]))\n",
    "                    home_spread.append(-float(spread_of_that_team[s]))\n",
    "\n",
    "                else:\n",
    "                 #   print(team + \" is at home\")\n",
    "                    home_spread.append(-float(spread_of_that_team[s]))\n",
    "    \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    ready_for_it = []\n",
    "    for i in range(len(todays_dataframe)):\n",
    "        ready = list(todays_dataframe[i])\n",
    "        ready.append(home_spread[i])\n",
    "        ready_for_it.append(ready)\n",
    "  # todays_dataframe[i] = list(todays_dataframe[i]).append(home_spread[i])\n",
    "\n",
    "    ready_for_it = np.array(ready_for_it)\n",
    "    \n",
    "    return matchups,ready_for_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meh = create_todays_dataset_p1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPREAD\n",
      "-4.5+4.5HOU: -110OKC: -110\n",
      "SPREAD\n",
      "-9.5+9.5BOS: -110PHX: -110\n",
      "SPREAD\n",
      "+5.5-5.5LAC: -110POR: -110\n",
      "SPREAD\n",
      "+6-6MIL: -110GS: -110\n",
      "TEAM THAT PLAYS:\n",
      "['HOU', 'BOS', 'LAC', 'MIL']\n"
     ]
    }
   ],
   "source": [
    "matchups, data = scrape_espn_for_today_spreads(meh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now import the machine learning model written in the models section, and predict the winners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "model_path = '../models/finalized_model.sav'\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)\n",
    "\n",
    "scaler_path = '../models/finalized_scaler.sav'\n",
    "loaded_scaler = pickle.load(open(scaler_path, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_today = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_today.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_today = loaded_scaler.transform(X_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spread2ML(spread):\n",
    "    \"\"\"Converts spread into a moneyline value using the equation I calculated. \n",
    "    \"\"\"\n",
    "    if spread <=1.5:\n",
    "        \n",
    "        ML = 1.71409498 * spread**3 + 10.90008433 * spread **2 + 22.40247106 * spread - 138.20112341\n",
    "    else: \n",
    "\n",
    "        ML = 1.66494668 * spread**3 -20.03302374 * spread**2 + 101.20347437 * spread - 34.68833849\n",
    "    \n",
    "    return ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game:  ['HOU', 'OKC']\n",
      "Spread of for :  OKC 4.5\n",
      "Moneylines:  HOU -174.48244055 OKC 166.776831655\n",
      "Winner:  OKC\n",
      "Line of prediction\n",
      "Game:  ['BOS', 'PHX']\n",
      "Spread of for :  PHX 9.5\n",
      "Moneylines:  BOS -836.914171175 PHX 546.247935255\n",
      "Winner:  BOS\n",
      "Line of prediction\n",
      "Game:  ['LAC', 'POR']\n",
      "Spread of for :  POR -5.5\n",
      "Moneylines:  LAC 192.937306295 POR -216.869715555\n",
      "Winner:  POR\n",
      "Line of prediction\n",
      "Game:  ['MIL', 'GSW']\n",
      "Spread of for :  GSW -6.0\n",
      "Moneylines:  MIL 210.97213597 GSW -250.45742957\n",
      "Winner:  GSW\n",
      "Line of prediction\n"
     ]
    }
   ],
   "source": [
    "spreads = data[:,-1]\n",
    "for i,game in enumerate(X_today):\n",
    "    prediction = loaded_model.predict([game])[0]\n",
    "    \n",
    "    print(\"Game: \", matchups[i])\n",
    "    print(\"Home Team Spread : \",matchups[i][1], spreads[i])\n",
    "    print(\"Approximate Moneyline Odds: \",matchups[i][0],spread2ML(-spreads[i]),matchups[i][1],spread2ML(spreads[i]))\n",
    "    print(\"Predicted Winner: \",matchups[i][prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Above contains the scraping necessary to create a dataset based on the games of today, and by downloading the model and scaling tool used in previous sections, allows for the capabilitiies to choose the winner of each game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOS', 'PHX']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchups[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.5,  9.5, -5.5, -6. ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreads = data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layed out below is how you would confirm the ordering is correct, and make sure the prediction is for the corresponding game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe1 = pd.DataFrame([])\n",
    "dataframe2 = pd.DataFrame([])\n",
    "dataframe1 = dataframe1.append(data)\n",
    "dataframe2 = matchups\n",
    "\n",
    "\n",
    "#df =  pd.mergexxxx\n",
    "\n",
    "\n",
    "#data3 = pd.DataFrame([])\n",
    "\n",
    "#data3 = games\n",
    "\n",
    "\n",
    "\n",
    "#pd. sort ....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dataframe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make  DataFrame, one of the splits, with an additional column as the home team. \n",
    "\n",
    "Now do the same with matchups, and sort the initial dataframe based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_that_plays = ['NYK', 'SAS', 'PHI', 'DEN', 'CHI', 'DAL', 'TOR', 'MIN', 'OKC', 'DET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([])\n",
    "actual_order = {}\n",
    "for team in team_that_plays:\n",
    "    print(team)\n",
    "    for t,game in enumerate(games):\n",
    "        if team in game:\n",
    "            print(\"In game\", t)\n",
    "            \n",
    "            actual_order[team] = t\n",
    "actual_order = sorted(actual_order.items(), key=lambda kv: kv[1])\n",
    "\n",
    "\n",
    "#Now need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(actual_order.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_order = sorted(actual_order.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([])\n",
    "data = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
