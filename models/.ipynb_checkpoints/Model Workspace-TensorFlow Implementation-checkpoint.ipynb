{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook serves a test workspace. For a more robust testing space, please check out the other notebook in this repo. This notebook is devoted to tensorflow, and trying to implement ML at a lower level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dependencies, and dataset. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../splits_optimizer/model_ready_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>road_Rolling FG</th>\n",
       "      <th>road_Rolling 3P</th>\n",
       "      <th>road_Rolling FT</th>\n",
       "      <th>road_Rolling DR</th>\n",
       "      <th>road_Rolling AST</th>\n",
       "      <th>road_Rolling ST</th>\n",
       "      <th>road_Rolling TO</th>\n",
       "      <th>road_Rolling BL</th>\n",
       "      <th>road_Rolling PTS</th>\n",
       "      <th>...</th>\n",
       "      <th>home_Rolling TO</th>\n",
       "      <th>home_Rolling BL</th>\n",
       "      <th>home_Rolling PTS</th>\n",
       "      <th>home_Rolling AST/TO</th>\n",
       "      <th>home_Rolling 3P%</th>\n",
       "      <th>home_Rolling FG%</th>\n",
       "      <th>home_Rolling FT%</th>\n",
       "      <th>home_SPREAD</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>Home Team Won?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.033333</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>17.366667</td>\n",
       "      <td>35.066667</td>\n",
       "      <td>25.966667</td>\n",
       "      <td>7.366667</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>5.766667</td>\n",
       "      <td>108.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>108.033333</td>\n",
       "      <td>1.916725</td>\n",
       "      <td>0.333378</td>\n",
       "      <td>0.458320</td>\n",
       "      <td>0.766028</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35.633333</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>29.066667</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>93.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>105.300000</td>\n",
       "      <td>1.909397</td>\n",
       "      <td>0.333049</td>\n",
       "      <td>0.465288</td>\n",
       "      <td>0.719054</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39.466667</td>\n",
       "      <td>8.533333</td>\n",
       "      <td>16.466667</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>23.233333</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>14.133333</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>103.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>13.533333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>106.433333</td>\n",
       "      <td>1.954478</td>\n",
       "      <td>0.337522</td>\n",
       "      <td>0.429603</td>\n",
       "      <td>0.794908</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.866667</td>\n",
       "      <td>5.033333</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>33.233333</td>\n",
       "      <td>19.766667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>5.366667</td>\n",
       "      <td>93.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>14.366667</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>93.133333</td>\n",
       "      <td>1.579379</td>\n",
       "      <td>0.346225</td>\n",
       "      <td>0.434064</td>\n",
       "      <td>0.771320</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>9.566667</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>103.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.566667</td>\n",
       "      <td>95.233333</td>\n",
       "      <td>1.347540</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>0.454824</td>\n",
       "      <td>0.770221</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  road_Rolling FG  road_Rolling 3P  road_Rolling FT  \\\n",
       "0           0        41.033333         8.966667        17.366667   \n",
       "1           1        35.633333         6.366667        15.600000   \n",
       "2           2        39.466667         8.533333        16.466667   \n",
       "3           3        34.866667         5.033333        18.500000   \n",
       "4           4        39.000000         9.566667        15.866667   \n",
       "\n",
       "   road_Rolling DR  road_Rolling AST  road_Rolling ST  road_Rolling TO  \\\n",
       "0        35.066667         25.966667         7.366667        14.200000   \n",
       "1        29.066667         19.800000         7.300000        14.233333   \n",
       "2        30.700000         23.233333         9.533333        14.133333   \n",
       "3        33.233333         19.766667         6.333333        12.700000   \n",
       "4        32.700000         25.800000         8.300000        14.600000   \n",
       "\n",
       "   road_Rolling BL  road_Rolling PTS       ...        home_Rolling TO  \\\n",
       "0         5.766667        108.400000       ...              13.600000   \n",
       "1         5.033333         93.233333       ...              13.500000   \n",
       "2         4.700000        103.933333       ...              13.533333   \n",
       "3         5.366667         93.266667       ...              14.366667   \n",
       "4         4.466667        103.433333       ...              15.000000   \n",
       "\n",
       "   home_Rolling BL  home_Rolling PTS  home_Rolling AST/TO  home_Rolling 3P%  \\\n",
       "0         3.766667        108.033333             1.916725          0.333378   \n",
       "1         4.633333        105.300000             1.909397          0.333049   \n",
       "2         2.866667        106.433333             1.954478          0.337522   \n",
       "3         4.966667         93.133333             1.579379          0.346225   \n",
       "4         4.566667         95.233333             1.347540          0.345794   \n",
       "\n",
       "   home_Rolling FG%  home_Rolling FT%  home_SPREAD  PLUS_MINUS  Home Team Won?  \n",
       "0          0.458320          0.766028          7.0          19               1  \n",
       "1          0.465288          0.719054        -14.5           8               1  \n",
       "2          0.429603          0.794908         -4.0          -2               0  \n",
       "3          0.434064          0.771320         -2.5           3               1  \n",
       "4          0.454824          0.770221         -3.0          -1               0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome = df['PLUS_MINUS'] #df['home_SPREAD'] + df['PLUS_MINUS'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for val in outcome:\n",
    "    if val>0: \n",
    "        y.append(1) #home team wins. \n",
    "    else:\n",
    "        y.append(0)\n",
    "        \n",
    "del df['PLUS_MINUS']\n",
    "\n",
    "\n",
    "X = df\n",
    "del X['Unnamed: 0']\n",
    "del X['Home Team Won?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The home team wins  59.038961038961034 % of the time. \n"
     ]
    }
   ],
   "source": [
    "hometeamwins = sum(y)/len(y)  \n",
    "print(\"The home team wins \", 100*hometeamwins, \"% of the time. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ready for data normalization and splitting\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Split all into training and testing\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=False,test_size = .25)\n",
    "#Set aside some training data for validation. \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,shuffle=False,test_size = .25)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#Normalization of dataset. \n",
    "scaler.fit(X_train.values)\n",
    "X_train = scaler.transform(X_train.values)\n",
    "X_val = scaler.transform(X_val.values)\n",
    "X_test = scaler.transform(X_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "import  tensorflow as tf\n",
    "tf.set_random_seed(456)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate tensorflow graph\n",
    "d = X_train.shape[1]\n",
    "n_hidden = 100\n",
    "learning_rate = .001\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "dropout_prob = .5\n",
    "\n",
    "\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    x = tf.placeholder(tf.float32, (None, d))\n",
    "    y = tf.placeholder(tf.float32, (None,))\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "with tf.name_scope(\"hidden-layer-1\"):\n",
    "    W = tf.Variable(tf.random_normal((d, n_hidden)))\n",
    "    b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "    x_hidden_1 = tf.nn.sigmoid(tf.matmul(x, W) + b)\n",
    "  # Apply dropout\n",
    "    x_hidden_1 = tf.nn.dropout(x_hidden_1, keep_prob)\n",
    "\n",
    "with tf.name_scope(\"hidden-layer-2\"):\n",
    "    W = tf.Variable(tf.random_normal((n_hidden, n_hidden)))\n",
    "    b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "    x_hidden_2 = tf.nn.sigmoid(tf.matmul(x_hidden_1, W) + b)\n",
    "  # Apply dropout\n",
    "    x_hidden_2 = tf.nn.dropout(x_hidden_2, keep_prob)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    W = tf.Variable(tf.random_normal((n_hidden, 1)))\n",
    "    b = tf.Variable(tf.random_normal((1,)))\n",
    "    y_logit = tf.matmul(x_hidden_2, W) + b\n",
    "  # the sigmoid gives the class probability of 1\n",
    "    y_one_prob = tf.sigmoid(y_logit)\n",
    "  # Rounding P(y=1) will give the correct prediction.\n",
    "    y_pred = tf.round(y_one_prob)\n",
    "with tf.name_scope(\"loss\"):\n",
    "  # Compute the cross-entropy term for each datapoint\n",
    "    y_expand = tf.expand_dims(y, 1)\n",
    "    entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)\n",
    "  # Sum all contributions\n",
    "    l = tf.reduce_sum(entropy)\n",
    "\n",
    "with tf.name_scope(\"optim\"):\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)\n",
    "\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    tf.summary.scalar(\"loss\", l)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Write to tensorboard\n",
    "train_writer = tf.summary.FileWriter('/tmp/nba-tf-neural-network',tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training acc.  0.645727482679 %\n",
      "training acc.  0.658198614319 %\n",
      "training acc.  0.667898383372 %\n",
      "training acc.  0.669284064665 %\n",
      "training acc.  0.672979214781 %\n",
      "training acc.  0.678983833718 %\n",
      "training acc.  0.676674364896 %\n",
      "training acc.  0.676674364896 %\n",
      "training acc.  0.68129330254 %\n",
      "training acc.  0.6896073903 %\n",
      "training acc.  0.683140877598 %\n",
      "training acc.  0.680369515012 %\n",
      "training acc.  0.683140877598 %\n",
      "training acc.  0.678060046189 %\n",
      "training acc.  0.680369515012 %\n",
      "training acc.  0.675750577367 %\n",
      "training acc.  0.673903002309 %\n",
      "training acc.  0.673903002309 %\n",
      "training acc.  0.672979214781 %\n",
      "training acc.  0.678060046189 %\n",
      "training acc.  0.674826789838 %\n",
      "training acc.  0.672055427252 %\n",
      "training acc.  0.671593533487 %\n",
      "training acc.  0.677598152425 %\n",
      "training acc.  0.683602771363 %\n",
      "training acc.  0.68545034642 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.693302540416 %\n",
      "training acc.  0.688683602771 %\n",
      "training acc.  0.695612009238 %\n",
      "training acc.  0.695150115473 %\n",
      "training acc.  0.672517321016 %\n",
      "training acc.  0.68129330254 %\n",
      "training acc.  0.673903002309 %\n",
      "training acc.  0.66974595843 %\n",
      "training acc.  0.660046189376 %\n",
      "training acc.  0.664203233256 %\n",
      "training acc.  0.660969976905 %\n",
      "training acc.  0.672055427252 %\n",
      "training acc.  0.670207852194 %\n",
      "training acc.  0.668360277136 %\n",
      "training acc.  0.674364896074 %\n",
      "training acc.  0.665127020785 %\n",
      "training acc.  0.673441108545 %\n",
      "training acc.  0.681755196305 %\n",
      "training acc.  0.686374133949 %\n",
      "training acc.  0.682217090069 %\n",
      "training acc.  0.68545034642 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.68129330254 %\n",
      "training acc.  0.685912240185 %\n",
      "training acc.  0.687759815242 %\n",
      "training acc.  0.684526558891 %\n",
      "training acc.  0.684064665127 %\n",
      "training acc.  0.690069284065 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.689145496536 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.69376443418 %\n",
      "training acc.  0.692840646651 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.696073903002 %\n",
      "training acc.  0.696073903002 %\n",
      "training acc.  0.693302540416 %\n",
      "training acc.  0.696073903002 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.694688221709 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.692378752887 %\n",
      "training acc.  0.692378752887 %\n",
      "training acc.  0.687759815242 %\n",
      "training acc.  0.689145496536 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.6896073903 %\n",
      "training acc.  0.6896073903 %\n",
      "training acc.  0.688221709007 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.69376443418 %\n",
      "training acc.  0.690993071594 %\n",
      "training acc.  0.696997690531 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.695612009238 %\n",
      "training acc.  0.69376443418 %\n",
      "training acc.  0.694688221709 %\n",
      "training acc.  0.686374133949 %\n",
      "training acc.  0.689145496536 %\n",
      "training acc.  0.6896073903 %\n",
      "training acc.  0.687759815242 %\n",
      "training acc.  0.689145496536 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.690069284065 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.6896073903 %\n",
      "training acc.  0.690531177829 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.691454965358 %\n",
      "training acc.  0.691454965358 %\n",
      "Train Classification Accuracy: 0.691455\n",
      "Test Classification Accuracy: 0.657321\n"
     ]
    }
   ],
   "source": [
    "#Begin iteration through batches of training data and see model improve. \n",
    "N = X_train.shape[0]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    step = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        pos = 0\n",
    "        while pos < N:\n",
    "            batch_X = X_train[pos:pos+batch_size]\n",
    "            batch_y = y_train[pos:pos+batch_size]\n",
    "            feed_dict = {x: batch_X, y: batch_y, keep_prob: dropout_prob}\n",
    "            _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)\n",
    "            train_writer.add_summary(summary, step)\n",
    "\n",
    "            step += 1\n",
    "            pos += batch_size\n",
    "  # Make Predictions (set keep_prob to 1.0 for predictions)\n",
    "        train_y_pred = sess.run(y_pred, feed_dict={x: X_train, keep_prob: 1.0})\n",
    "       # val_y_pred = sess.run(y_pred, feed_dict={x: X_val, keep_prob: 1.0})\n",
    "        #print(\"epoch %d, step %d, loss: %f\" % (epoch, step, loss))\n",
    "        print(\"training acc. \", accuracy_score(y_train,train_y_pred), \"%\")\n",
    "      #  print(\"validation acc. \", accuracy_score(y_val,val_y_pred), \"%\")\n",
    "    test_y_pred = sess.run(y_pred, feed_dict={x: X_test, keep_prob: 1.0})\n",
    "\n",
    "train_score = accuracy_score(y_train, train_y_pred)\n",
    "print(\"Train Classification Accuracy: %f\" % train_score)\n",
    "#valid_weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "#print(\"Valid Weighted Classification Accuracy: %f\" % valid_weighted_score)\n",
    "test_score = accuracy_score(y_test, test_y_pred)\n",
    "print(\"Test Classification Accuracy: %f\" % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW1107 18:26:22.767660 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:22.768768 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:22.776395 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:22.777164 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mTensorBoard 1.7.0a20180302 at http://Noahs-MBP.fios-router.home:6006 (Press CTRL+C to quit)\n",
      "\u001b[33mW1107 18:26:27.124647 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:27.125793 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:28.355529 Reloader tf_logging.py:121] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0m\u001b[33mW1107 18:26:28.356469 Reloader tf_logging.py:121] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=/tmp/nba-tf-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion. The tensorflow model clearly improves, but leaves a lot left to desire. The difference of nearly 4% between training and testing suggests there is some overfitting put in place. To remedy this, regularization techniques such as cross validation and others are put in place in the next notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# as a bonus, I did notice something initially wrong with my tensorflow model. I've included a picture of the losses graph that helped me debug the issue, and is discussed further in the README. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
